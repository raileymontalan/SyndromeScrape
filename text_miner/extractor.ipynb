{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, pprint, spacy, string\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from word2number import w2n\n",
    "from dateutil import parser\n",
    "from difflib import SequenceMatcher\n",
    "from jellyfish import jaro_winkler\n",
    "from spacy import *\n",
    "from spacy.pipeline import *\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load trained model, data, and psgc\n",
    "nlp = spacy.load('models')\n",
    "df = pd.read_json('test_data.json')\n",
    "psgc = pd.read_csv('psgc.csv', encoding='latin1')\n",
    "provinces = psgc.loc[:, 'Province': 'Province Code'].drop_duplicates()\n",
    "municipalities = psgc.loc[:, 'Municipality': 'Municipality Code'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_json(record, f):\n",
    "    if record == 'incident':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'code': str(f[5]),\n",
    "            'incident': w2n.word_to_num(str(f[6]))\n",
    "        }\n",
    "    elif record == 'state':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'code': str(f[5]),\n",
    "            'state': str(f[6])\n",
    "        }\n",
    "    elif record == 'change':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'code': str(f[5]),\n",
    "            'change': str(f[6])\n",
    "        }\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of tuples composed of the name\n",
    "# and type of the location\n",
    "\n",
    "def extract_location(text, ref=False):\n",
    "    locs = []\n",
    "    \n",
    "    # Retrieves the location specified at the start of each article\n",
    "    if ref:\n",
    "        for word in text:\n",
    "            if word.is_punct:\n",
    "                continue\n",
    "            elif word.ent_type_ == 'GPE':\n",
    "                locs.append(str(word))\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    # Retrieves the location found in any given sentence\n",
    "    else:\n",
    "        for word in text:\n",
    "            if word not in STOP_WORDS:\n",
    "                if word.ent_type_ == 'GPE':\n",
    "                    locs.append(str(word))\n",
    "    out = search(psgc, locs)     \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(data, locations):\n",
    "    if locations:\n",
    "        # remove instances of \"Philippines\"\n",
    "        if 'Philippines' in locations:\n",
    "            locations.remove('Philippines')\n",
    "    \n",
    "        # fuzzy search for each line; keep the options with the highest similarity\n",
    "        possible_locs = []\n",
    "    \n",
    "        for loc in locations:\n",
    "            max_similarity = 0\n",
    "            locs = []\n",
    "            final_locs = []\n",
    "        \n",
    "            # go through all provinces before municipalities\n",
    "            for _, province in provinces.iterrows():\n",
    "                jaro_distance = jaro_winkler(province[0].lower(), loc.lower())\n",
    "                #jaro_distance = SequenceMatcher(None, province[0].lower(), loc.lower()).ratio()\n",
    "\n",
    "                # if current similarity is higher than stored max similarity,\n",
    "                # replace all area codes in locs[] with current and update max_similarity\n",
    "                if jaro_distance > max_similarity:\n",
    "                    locs = [province[1]]\n",
    "                    max_similarity = jaro_distance\n",
    "\n",
    "                # if current similarity is equal to the stored max similarity,\n",
    "                # append current area code to locs[]\n",
    "                elif int(jaro_distance) == int(max_similarity):\n",
    "                    locs.append(province[1])\n",
    "\n",
    "            # append locs[] to final_locs[] only if similarity is acceptable\n",
    "            if max_similarity >= 0.5:\n",
    "                final_locs += locs\n",
    "        \n",
    "            max_similarity = 0\n",
    "            \n",
    "            # go through all municipalities\n",
    "            for _, municipal in municipalities.iterrows():\n",
    "                jaro_distance = SequenceMatcher(None, municipal[0].lower(), loc.lower()).ratio()\n",
    "\n",
    "                # if current similarity is higher than stored max similarity,\n",
    "                # replace all area codes in locs[] with current and update max_similarity\n",
    "                if jaro_distance > max_similarity:\n",
    "                    locs = [municipal[1]]\n",
    "                    max_similarity = jaro_distance\n",
    "\n",
    "                # if current similarity is equal to the stored max similarity,\n",
    "                # append current area code to locs[]\n",
    "                elif jaro_distance == max_similarity:\n",
    "                    locs.append(municipal[1])\n",
    "\n",
    "            # append locs[] to final_locs[] only if similarity is acceptable\n",
    "            if max_similarity >= 0.5:\n",
    "                final_locs += locs\n",
    "\n",
    "            possible_locs.append(final_locs)\n",
    "        \n",
    "        # find intersecting rows for all locations\n",
    "        possible_locations = []\n",
    "    \n",
    "        try:\n",
    "            _ = possible_locs[1]\n",
    "\n",
    "            if len(possible_locs) > 1:\n",
    "                for loc in possible_locs[0]:\n",
    "                    for loc2 in possible_locs[1]:\n",
    "                        if str(loc2)[:-5] == str(loc)[:-5]:\n",
    "                            possible_locations += [loc, loc2]\n",
    "        except IndexError:\n",
    "            #return '0' + str(possible_locs[0][0])[:-5] + '00000'\n",
    "            return '0' + str(possible_locs[0])[:-5] + '00000'\n",
    "\n",
    "        # choose highest similarity\n",
    "        possible_locations = list(set(possible_locations))\n",
    "        return (str(possible_locations[0])[:-5] + '00000').zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    count\n",
    "\"\"\"\n",
    "def extract_incident(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    relations = []\n",
    "    \n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    #if extracted_loc:\n",
    "    #    loc = search(extracted_loc)\n",
    "        \n",
    "    # Find all CARDINAL entities, then check if they are \n",
    "    # linked to a disease, case, or location\n",
    "    # If they are, they are probably incidence counts\n",
    "    for number in filter(lambda w: w.ent_type_ == 'CARDINAL', sent):\n",
    "        if number.dep_ in ('attr', 'dobj'):\n",
    "            case = [w for w in number.head.lefts if w.ent_type == 'nsubj']\n",
    "            if case: \n",
    "                count = number.text.replace(',', '')\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, loc, count]))\n",
    "        else:\n",
    "            case = number.head.ent_type_\n",
    "            count = number.text.replace(',', '')\n",
    "            if case == 'CASE':\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, loc, count]))\n",
    "            if case == 'LOC':\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, loc, count]))\n",
    "            \n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    state\n",
    "\"\"\"\n",
    "def extract_status(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    relations = []\n",
    "    \n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    #if extracted_loc:\n",
    "    #    loc = search(extracted_loc)\n",
    "    \n",
    "    ## I need to find a way to locate a substring of STATE tokens,\n",
    "    ## concatenate the token.text of each token into one string\n",
    "    ## then append it into the relations list\n",
    "    \n",
    "    ## this one here doesn't implement that yet vvv\n",
    "    states = filter(lambda x: x.ent_type_ == 'STATE', sent)\n",
    "    state = ' '.join(map(str, states))\n",
    "    if state:\n",
    "        if 'hot' in state:\n",
    "            state = 'hot'\n",
    "        elif 'calamity' in state:\n",
    "            state = 'calamity'\n",
    "        elif 'outbreak' in state or 'epidemic' in state:\n",
    "            state = 'outbreak'\n",
    "        relations.append(record_to_json('state', [dis, date_start, date_end, title, url, loc, state]))\n",
    "        \n",
    "    return relations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    change\n",
    "\"\"\"\n",
    "def extract_change(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    relations = []\n",
    "    \n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    #if extracted_loc:\n",
    "    #    loc = search(extracted_loc)\n",
    "    \n",
    "    for change in filter(lambda w: w.ent_type_ == 'CHANGE', sent):\n",
    "        for child in change.children:\n",
    "            if child.ent_type_ == 'PERCENT':\n",
    "                if str(change) in ['high, higher', 'increase', 'increasing', 'increased', 'rise', 'rose', 'more']:\n",
    "                    change = 'rise'\n",
    "                elif str(change) in ['low', 'lower', 'decrease', 'decreasing', 'decreased', 'fall', 'fell', 'less']:\n",
    "                    change = 'fall'\n",
    "                relations.append(record_to_json('change', [dis, date_start, date_end, title, url, loc, change]))\n",
    "                \n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_refs(article):\n",
    "    dis = article['disease']\n",
    "    date = article['timestamp'] \n",
    "    title = article['title']\n",
    "    url = article['url']\n",
    "    loc = extract_location(nlp(article['content']), ref=True)\n",
    "    #loc = extract_location(nlp(article['content']), ref=True)\n",
    "    return [dis, date, title, url, loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    total_incidents = []\n",
    "    total_statuses = []\n",
    "    total_changes = []\n",
    "    for index, article in df.iterrows():\n",
    "        doc = nlp(article['content'])\n",
    "        refs = extract_refs(article)\n",
    "        deets = [article['title'], article['url']]\n",
    "        incidents = []\n",
    "        statuses = []\n",
    "        changes = []\n",
    "        for sent in doc.sents:\n",
    "            i = extract_incident(sent,  refs)\n",
    "            s = extract_status(sent, refs)\n",
    "            t = extract_change(sent, refs)\n",
    "            if i: [incidents.append(x) for x in i]\n",
    "            if s: [statuses.append(x) for x in s]\n",
    "            if t: [changes.append(x) for x in t]\n",
    "        #if incidents: pp.pprint(incidents)\n",
    "        #if statuses: pp.print(statuses)\n",
    "        #if changes: pp.print(changes)\n",
    "    #\"\"\"\n",
    "        if incidents: [total_incidents.append(y) for y in incidents]\n",
    "        if statuses: [total_statuses.append(y) for y in statuses]\n",
    "        if changes: [total_changes.append(y) for y in changes]\n",
    "    \n",
    "    with open('incidents2.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_incidents, outfile, indent=4, ensure_ascii=False)\n",
    "    with open('statuses2.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_statuses, outfile, indent=4, ensure_ascii=False)\n",
    "    with open('changes2.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_changes, outfile, indent=4, ensure_ascii=False)\n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-210f6d6f4a00>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(data, locations)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossible_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-18a5709e9af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-250-cefbe22bbab2>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mchanges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_incident\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-f38b393f9cbc>\u001b[0m in \u001b[0;36mextract_incident\u001b[0;34m(sent, refs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrelations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mextracted_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Look for location specified in the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#if extracted_loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#    loc = search(extracted_loc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-224-49b3ffb83eb4>\u001b[0m in \u001b[0;36mextract_location\u001b[0;34m(text, ref)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_type_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mlocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-245-210f6d6f4a00>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(data, locations)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#return '0' + str(possible_locs[0][0])[:-5] + '00000'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'0'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'00000'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# choose highest similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "extract(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"2325\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dengue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fever,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">usually</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">fatal,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">caused</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">bite</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">Aedes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">mosquito.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M595,352.0 C595,89.5 1095.0,89.5 1095.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,354.0 L1103.0,342.0 1087.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1260.0,354.0 L1268.0,342.0 1252.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,354.0 L1623.0,342.0 1607.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,354.0 L1968.0,342.0 1952.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-11\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,2.0 2150.0,2.0 2150.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-11\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,354.0 L2158.0,342.0 2142.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\"\"\"\n",
    "test = nlp(df['content'][0])\n",
    "sents = [sent.as_doc() for sent in test.sents]\n",
    "displacy.render(sents[2], style='dep', jupyter=True)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a = nlp(df['content'][7])\n",
    "displacy.render(a, style='ent', jupyter=True)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
