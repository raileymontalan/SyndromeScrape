{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy, random\n",
    "from pathlib import Path\n",
    "from toolz import partition_all\n",
    "from spacy import *\n",
    "from spacy.gold import *\n",
    "from spacy.scorer import *\n",
    "from spacy.language import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load spaCy 'en' model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load unprocessed texts, apply nlp() to each text\n",
    "### then store into a list called docs.\n",
    "df = pd.read_json('train_data.json')\n",
    "texts = [text for text in df['content'][:6]]\n",
    "docs = [nlp.make_doc(text) for text in df['content'][:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of list of tuples called tuned_ents,\n",
    "### then store it as a JSON file. Each tuple represents a \n",
    "### fine-tuned entity for each diven doc. Each inner list\n",
    "### represents all the fine-tuned entities in each doc.\n",
    "tuned_ents = []\n",
    "tuned_ents.append([(0, 7, 'GPE'), (9, 20, 'GPE'), (66, 78, 'LOC_TYPE'), (82, 86, 'GPE'), (90, 97, 'GPE'),\n",
    "                   (98, 106, 'LOC_TYPE'), (123, 134, 'GPE'), (152, 169, 'STATE'), (205, 207, 'CARDINAL'),\n",
    "                   (208, 213, 'CASE'), (217, 223, 'DISEASE'), (227, 249, 'DATE'), (251, 257, 'DISEASE'),\n",
    "                   (384, 388, 'GPE'), (415, 431, 'DATE'), (437, 443, 'CASE'), (447, 452, 'CASE'), (466, 475, 'DATE'),\n",
    "                   (480, 501, 'CHANGE'), (518, 525, 'CASE'), (538, 552, 'DATE'), (556, 570, 'DATE'),\n",
    "                   (712, 739, 'STATE'), (913, 921, 'CARDINAL'), (929, 931, 'CARDINAL'), (932, 941, 'LOC_TYPE'),\n",
    "                   (943, 951, 'LOC_TYPE'), (960, 964, 'LOC_TYPE'), (1154, 1159, 'DATE'), (1165, 1185, 'ORG'),\n",
    "                   (1187, 1190, 'ORG'), (1201, 1206, 'PERCENT'), (1207, 1215, 'CHANGE'), (1219, 1225, 'DISEASE'),\n",
    "                   (1226, 1231, 'CASE'), (1239, 1246, 'LOC_TYPE'), (1255, 1261, 'CARDINAL'), (1262, 1267, 'CASE'),\n",
    "                   (1271, 1296, 'DATE'), (1302, 1308, 'CASE'), (1317, 1320, 'CARDINAL'), (1324, 1339, 'GPE'),\n",
    "                   (1346, 1356, 'GPE'), (1378, 1383, 'CARDINAL'), (1392, 1428, 'GPE'), (1430, 1434, 'GPE'),\n",
    "                   (1456, 1459, 'CARDINAL'), (1677, 1683, 'CASE'), (1687, 1693, 'DISEASE'), (1694, 1699, 'CASE'),\n",
    "                   (1711, 1740, 'DATE')\n",
    "                  ])\n",
    "tuned_ents.append([(0, 6, 'GPE'), (8, 19, 'GPE'), (26, 32, 'CASE'), (36, 42, 'DISEASE'), (43, 48, 'CASE'),\n",
    "                   (68, 83, 'LOC_TYPE'), (94, 100, 'CASE'), (104, 119, 'CARDINAL'), (131, 135, 'CASE'),\n",
    "                   (139, 150, 'CARDINAL'), (179, 195, 'DATE'), (201, 207, 'CASE'), (237, 259, 'DISEASE'),\n",
    "                   (263, 269, 'GPE'), (270, 279, 'DATE'), (291, 294, 'PERCENT'), (295, 301, 'CHANGE'),\n",
    "                   (307, 332, 'DATE'), (407, 413, 'DISEASE'), (414, 424, 'CASE'), (428, 450, 'DATE'),\n",
    "                   (464, 469, 'CHANGE'), (483, 489, 'CASE'), (494, 511, 'DATE'), (524, 532, 'STATE'),\n",
    "                   (536, 548, 'LOC_TYPE'), (748, 756, 'STATE'), (859, 865, 'DISEASE'), (1123, 1134, 'CARDINAL'),\n",
    "                   (1618, 1624, 'DISEASE'), (1661, 1672, 'GPE'), (1684, 1690, 'CASE'), (1694, 1703, 'CASE'),\n",
    "                   (1704, 1713, 'DATE'), (1717, 1731, 'CHANGE'), (1732, 1742, 'LOC_TYPE'), (1756, 1763, 'CHANGE'),\n",
    "                   (1775, 1780, 'LOC_TYPE'), (1789, 1795, 'GPE')\n",
    "                  ])\n",
    "tuned_ents.append([(0, 10, 'GPE'), (12, 23, 'GPE'), (37, 42, 'CARDINAL'), (43, 49, 'DISEASE'), (50, 55, 'CASE'),\n",
    "                   (80, 115, 'DATE'), (120, 128, 'CHANGE'), (132, 146, 'PERCENT'), (152, 163, 'DATE'),\n",
    "                   (174, 178, 'DATE'), (183, 202, 'ORG'), (225, 228, 'CARDINAL'), (229, 234, 'CASE'),\n",
    "                   (242, 257, 'DATE'), (316, 326, 'GPE'), (329, 342, 'ORG'), (375, 381, 'CASE'), (385, 394, 'CASE'),\n",
    "                   (395, 404, 'DATE'), (425, 444, 'DATE'), (446, 451, 'CARDINAL'), (452, 457, 'CASE'),\n",
    "                   (470, 472, 'CARDINAL'), (473, 479, 'DISEASE'), (480, 487, 'CASE'), (493, 501, 'LOC_TYPE'),\n",
    "                   (518, 525, 'DATE'), (625, 631, 'DISEASE'), (660, 674, 'DATE'), (1292, 1309, 'ORG'),\n",
    "                   (1319, 1335, 'ORG'), (1482, 1498, 'ORG'), (1534, 1542, 'LOC_TYPE'), (1550, 1554, 'LOC_TYPE')\n",
    "                  ])\n",
    "tuned_ents.append([(0, 6, 'GPE'), (8, 19, 'GPE'), (30, 35, 'GPE'), (36, 42, 'LOC_TYPE'), (70, 78, 'CHANGE'),\n",
    "                   (82, 88, 'DISEASE'), (89, 94, 'CASE'), (138, 142, 'CHANGE'), (146, 150, 'PERCENT'),\n",
    "                   (151, 160, 'DATE'), (166, 186, 'ORG'), (190, 199, 'GPE'), (239, 244, 'CARDINAL'),\n",
    "                   (245, 251, 'DISEASE'), (252, 257, 'CASE'), (258, 288, 'DATE'), (290, 292, 'CHANGE'),\n",
    "                   (298, 308, 'CARDINAL'), (309, 314, 'CASE'), (322, 347, 'DATE'), (508, 511, 'PERCENT'),\n",
    "                   (519, 524, 'CARDINAL'), (525, 530, 'CASE'), (541, 546, 'GPE'), (583, 592, 'LOC_TYPE'), \n",
    "                   (597, 602, 'LOC_TYPE'), (604, 615, 'CARDINAL'), (616, 620, 'CASE'), (624, 630, 'DISEASE'),\n",
    "                   (638, 642, 'LOC_TYPE'), (661, 685, 'ORG'), (757, 768, 'CHANGE'), (788, 809, 'DATE'),\n",
    "                   (831, 835, 'PERCENT'), (837, 845, 'CHANGE'), (850, 863, 'STATE'), (882, 892, 'LOC_TYPE'),\n",
    "                   (935, 940, 'CASE'), (948, 961, 'STATE'), (1080, 1090, 'LOC_TYPE'), (1226, 1234, 'STATE')])\n",
    "tuned_ents.append([(0, 7, 'GPE'), (9, 20, 'GPE'), (25, 31, 'DISEASE'), (32, 40, 'STATE'), (57, 72, 'GPE'),\n",
    "                   (76, 91, 'DATE'), (131, 132, 'CARDINAL'), (133, 143, 'CASE'), (149, 150, 'CARDINAL'), \n",
    "                   (151, 161, 'CASE'), (169, 170, 'CARDINAL'), (181, 189, 'LOC_TYPE'), (300, 314, 'DATE'),\n",
    "                   (316, 321, 'CASE'), (331, 337, 'CHANGE'), (343, 361, 'ORG'), (376, 379, 'CARDINAL'),\n",
    "                   (380, 385, 'CASE'), (392, 399, 'DATE'), (421, 422, 'CARDINAL'), (423, 433, 'CASE'),\n",
    "                   (468, 476, 'STATE'), (504, 507, 'CARDINAL'), (508, 513, 'CASE'), (523, 525, 'CARDINAL'),\n",
    "                   (526, 531, 'CASE'), (550, 556, 'DISEASE'), (560, 570, 'GPE'), (811, 814, 'CARDINAL'),\n",
    "                   (911, 926, 'DATE'), (936, 940, 'LOC_TYPE'), (944, 958, 'GPE'), (965, 977, 'LOC_TYPE'),\n",
    "                   (981, 985, 'GPE'), (989, 996, 'GPE'), (997, 1005, 'LOC_TYPE'), (1019, 1036, 'STATE'),\n",
    "                   (1070, 1072, 'CARDINAL'), (1073, 1078, 'CASE'), (1082, 1088, 'DISEASE'), (1097, 1114, 'DATE'),\n",
    "                   (1119, 1144, 'DATE'), (1150, 1167, 'ORG'), (1177, 1183, 'CARDINAL'), (1184, 1189, 'CASE'),\n",
    "                   (1193, 1199, 'DISEASE'), (1200, 1210, 'LOC_TYPE'), (1215, 1221, 'DATE'), (1223, 1230, 'GPE'),\n",
    "                   (1384, 1390, 'DATE'), (1396, 1420, 'ORG'), (1436, 1439, 'CARDINAL'), (1440, 1445, 'CASE'),\n",
    "                   (1449, 1455, 'DISEASE'), (1463, 1471, 'LOC_TYPE'), (1478, 1485, 'DATE'), (1492, 1493, 'CARDINAL'),\n",
    "                   (1494, 1500, 'CASE'), (1504, 1517, 'GPE'), (1532, 1538, 'DISEASE'), (1539, 1544, 'DISEASE'),\n",
    "                   (1545, 1550, 'CASE')])\n",
    "tuned_ents.append([(0, 6, 'GPE'), (8, 19, 'GPE'), (26, 46, 'ORG'), (48, 51, 'ORG'), (61, 68, 'DATE'),\n",
    "                   (113, 119, 'CARDINAL'), (130, 136, 'DISEASE'), (137, 142, 'CASE'), (146, 157, 'LOC_TYPE'),\n",
    "                   (158, 190, 'DATE'), (200, 205, 'PERCENT'), (206, 212, 'CHANGE'), (225, 248, 'DATE'),\n",
    "                   (250, 256, 'CARDINAL'), (283, 286, 'CARDINAL'), (294, 298, 'CASE'), (300, 306, 'DISEASE'),\n",
    "                   (454, 479, 'ORG'), (485, 496, 'GPE'), (620, 637, 'ORG'), (651, 657, 'DISEASE'),\n",
    "                   (658, 663, 'CASE'), (667, 678, 'LOC_TYPE'), (689, 699, 'GPE'), (701, 706, 'PERCENT'),\n",
    "                   (709, 724, 'GPE'), (726, 730, 'PERCENT'), (733, 750, 'GPE'), (753, 757, 'PERCENT'),\n",
    "                   (759, 774, 'GPE'), (779, 791, 'GPE'), (793, 797, 'PERCENT'), (804, 817, 'GPE'),\n",
    "                   (819, 823, 'PERCENT'), (836, 839, 'CARDINAL'), (861, 867, 'DISEASE'), (868, 873, 'CASE'),\n",
    "                   (878, 888, 'LOC_TYPE'), (890, 896, 'DISEASE'), (897, 902, 'CASE'), (1102, 1117, 'GPE'),\n",
    "                   (1141, 1147, 'CASE'), (1151, 1157, 'CASE'), (1158, 1167, 'DATE'), (1174, 1176, 'CARDINAL'),\n",
    "                   (1186, 1192, 'CASE'), (1199, 1207, 'DATE'), (1213, 1216, 'ORG'), (1247, 1249, 'CARDINAL'),\n",
    "                   (1250, 1259, 'LOC_TYPE'), (1261, 1269, 'LOC_TYPE'), (1274, 1285, 'LOC_TYPE'),\n",
    "                   (1289, 1295, 'DISEASE'), (1309, 1318, 'STATE'), (1331, 1335, 'LOC_TYPE'), (1351, 1360, 'CARDINAL'),\n",
    "                   (1361, 1367, 'DISEASE'), (1368, 1375, 'CASE'), (1522, 1528, 'DISEASE'), (1529, 1537, 'STATE'),\n",
    "                   (1547, 1554, 'LOC_TYPE')])\n",
    "#tuned_ents.append([(0, 6, 'GPE'), (8, 19, 'GPE'), (32, 38, 'CASE'), (42, 48, 'DISEASE'), (49, 54, 'CASE'), (58, 69, 'LOC_TYPE'), (70, 79, 'CHANGE')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Add labels in tuned_ents to the model\n",
    "for text_ents in tuned_ents:\n",
    "    for ents in text_ents:\n",
    "        nlp.get_pipe('ner').add_label(ents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of tuples called crude_data. Apply nlp() to\n",
    "### Each tuple is made up of a text, and a GoldParse object\n",
    "### of the text itself.\n",
    "crude_data = []\n",
    "for i in range(6):\n",
    "    crude_data.append((docs[i], GoldParse(docs[i])))\n",
    "    #print(GoldParse(docs[i]).ner)\n",
    "#crude_data = [(doc, GoldParse(doc)) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Create a list of tuples called tuned_data. The tuple's\n",
    "### GoldParse object uses the fine-tuned entities found in\n",
    "### the list callen tuned_ents.\n",
    "tuned_data = []\n",
    "for i in range(6):\n",
    "#for i in range(len(docs)):\n",
    "    gold = GoldParse(docs[i], entities=tuned_ents[i])\n",
    "    tuned_data.append((docs[i], gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Train the model using crude_data and tuned_data.\n",
    "n_epoch = 20\n",
    "batch_size = 10\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_epoch):\n",
    "        data = crude_data + tuned_data\n",
    "        losses = {}\n",
    "        for batch in partition_all(batch_size, data):\n",
    "            docs, golds = zip(*batch)\n",
    "            nlp.update(docs, golds, sgd=optimizer, drop=0.35, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved modelfassster_news to models\n"
     ]
    }
   ],
   "source": [
    "### Save new model\n",
    "new_model = 'fassster_news'\n",
    "out_dir = 'models'\n",
    "nlp.meta['name'] = new_model\n",
    "nlp.to_disk(out_dir)\n",
    "print('Saved model' + new_model + ' to ' + out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models\n"
     ]
    }
   ],
   "source": [
    "### Load new model\n",
    "print('Loading model from', out_dir)\n",
    "nlp2 = spacy.load(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, texts, annotations):\n",
    "    scorer = Scorer()\n",
    "    for i in range(len(annotations)):\n",
    "        gold = GoldParse(nlp.make_doc(texts[i]), entities=annotations[i])\n",
    "        prediction = model(texts[i])\n",
    "        scorer.score(prediction, gold)\n",
    "    return scorer.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_f': 81.35593220338983,\n",
       " 'ents_p': 85.71428571428571,\n",
       " 'ents_r': 77.41935483870968,\n",
       " 'las': 0.0,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0,\n",
       " 'uas': 0.0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ents_f: fscore\n",
    "ents_p: precision\n",
    "ents_r: recall\n",
    "'''\n",
    "evaluate(nlp2, texts, tuned_ents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
