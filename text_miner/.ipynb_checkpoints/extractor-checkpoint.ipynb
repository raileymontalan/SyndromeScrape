{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, pprint, spacy, string\n",
    "from pathlib import Path\n",
    "from dateutil import parser\n",
    "from spacy import *\n",
    "from spacy.pipeline import *\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load trained model and data\n",
    "nlp = spacy.load('models')\n",
    "df = pd.read_json('test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_json(record, f):\n",
    "    if record == 'incident':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'geocode': str(f[5]),\n",
    "            'incident': str(f[6])\n",
    "        }\n",
    "    elif record == 'state':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'geocode': str(f[5]),\n",
    "            'state': str(f[6])\n",
    "        }\n",
    "    elif record == 'trend':\n",
    "        return {\n",
    "            'disease': str(f[0]),\n",
    "            'date-start': str(f[1]),\n",
    "            'date-end': str(f[2]),\n",
    "            'title': str(f[3]),\n",
    "            'url': str(f[4]),\n",
    "            'geocode': str(f[5]),\n",
    "            'trend': str(f[6])\n",
    "        }\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geolocate(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of tuples composed of the name\n",
    "# and type of the location\n",
    "\n",
    "def extract_location(text, ref=False):\n",
    "    locs = []\n",
    "    \n",
    "    # Retrieves the location specified at the start of each article\n",
    "    if ref:\n",
    "        for word in text:\n",
    "            if word.is_punct:\n",
    "                continue\n",
    "            elif word.ent_type_ == 'GPE':\n",
    "                locs.append(word)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    # Retrieves the location found in any given sentence\n",
    "    else:\n",
    "        for word in text:\n",
    "            if word not in STOP_WORDS:\n",
    "                if word.ent_type_ == 'GPE' or word.ent_type_ == 'LOC_TYPE':\n",
    "                    locs.append(word)\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    count\n",
    "\"\"\"\n",
    "def extract_incident(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    relations = []\n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    \n",
    "    # Find all CARDINAL entities, then check if they are \n",
    "    # linked to a disease, case, or location\n",
    "    # If they are, they are probably incidence counts\n",
    "    for number in filter(lambda w: w.ent_type_ == 'CARDINAL', sent):\n",
    "        if number.dep_ in ('attr', 'dobj'):\n",
    "            case = [w for w in number.head.lefts if w.ent_type == 'nsubj']\n",
    "            if case: \n",
    "                count = number.text.replace(',', '')\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, geolocate(loc), count]))\n",
    "        else:\n",
    "            case = number.head.ent_type_\n",
    "            count = number.text.replace(',', '')\n",
    "            if case == 'CASE':\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, geolocate(loc), count]))\n",
    "            if case == 'LOC':\n",
    "                relations.append(record_to_json('incident', [dis,  date_start, date_end, title, url, geolocate(loc), count]))\n",
    "            \n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    state\n",
    "\"\"\"\n",
    "def extract_status(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    relations = []\n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    \n",
    "    ## I need to find a way to locate a substring of STATE tokens,\n",
    "    ## concatenate the token.text of each token into one string\n",
    "    ## then append it into the relations list\n",
    "    \n",
    "    ## this one here doesn't implement that yet vvv\n",
    "    states = filter(lambda x: x.ent_type_ == 'STATE', sent)\n",
    "    state = ' '.join(map(str, states))\n",
    "    \n",
    "    if extracted_loc: loc = extracted_loc\n",
    "    if state: relations.append(record_to_json('state', [dis, date_start, date_end, title, url, geolocate(loc), state]))\n",
    "    return relations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "features:\n",
    "    disease\n",
    "    date\n",
    "    title\n",
    "    url\n",
    "    geocode\n",
    "    change\n",
    "\"\"\"\n",
    "def extract_trend(sent, refs):\n",
    "    # Load metadata values\n",
    "    dis, date, title, url, loc = refs\n",
    "    date_start = date.strftime('%Y-%m-%d')\n",
    "    date_end = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    relations = []\n",
    "    extracted_loc = extract_location(sent) # Look for location specified in the sentence\n",
    "    \n",
    "    for change in filter(lambda w: w.ent_type_ == 'CHANGE', sent):\n",
    "        for child in change.children:\n",
    "            if child.ent_type_ == 'PERCENT':\n",
    "                relations.append(record_to_json('trend', [dis, date_start, date_end, title, url, geolocate(loc), change]))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_refs(article):\n",
    "    dis = article['disease']\n",
    "    date = article['timestamp'] \n",
    "    title = article['title']\n",
    "    url = article['url']\n",
    "    loc = extract_location(nlp(article['content']), ref=True)\n",
    "    return [dis, date, title, url, loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    total_incidents = []\n",
    "    total_statuses = []\n",
    "    total_trends = []\n",
    "    for index, article in df.iterrows():\n",
    "        doc = nlp(article['content'])\n",
    "        refs = extract_refs(article)\n",
    "        deets = [article['title'], article['url']]\n",
    "        incidents = []\n",
    "        statuses = []\n",
    "        trends = []\n",
    "        for sent in doc.sents:\n",
    "            i = extract_incident(sent,  refs)\n",
    "            s = extract_status(sent, refs)\n",
    "            t = extract_trend(sent, refs)\n",
    "            if i: [incidents.append(x) for x in i]\n",
    "            if s: [statuses.append(x) for x in s]\n",
    "            if t: [trends.append(x) for x in t]\n",
    "        if incidents: pprint(index, incidents)\n",
    "        #if statuses: print(index, statuses)\n",
    "        #if trends: print(index, trends)\n",
    "    \"\"\"\n",
    "        if incidents: [total_incidents.append(y) for y in incidents]\n",
    "        if statuses: [total_statuses.append(y) for y in statuses]\n",
    "        if trends: [total_trends.append(y) for y in trends]\n",
    "    \n",
    "    with open('incidents.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_incidents, outfile, indent=4, ensure_ascii=False)\n",
    "    with open('statuses.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_statuses, outfile, indent=4, ensure_ascii=False)\n",
    "    with open('trends.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(total_trends, outfile, indent=4, ensure_ascii=False)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-653810a84bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#if trends: print(index, trends)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-653810a84bce>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(article)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mincidents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincidents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#if statuses: print(index, statuses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#if trends: print(index, trends)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "def extract(article):\n",
    "    total_incidents = []\n",
    "    total_statuses = []\n",
    "    total_trends = []\n",
    "    doc = nlp(article['content'])\n",
    "    refs = extract_refs(article)\n",
    "    deets = [article['title'], article['url']]\n",
    "    incidents = []\n",
    "    statuses = []\n",
    "    trends = []\n",
    "    for sent in doc.sents:\n",
    "        i = extract_incident(sent,  refs)\n",
    "        s = extract_status(sent, refs)\n",
    "        t = extract_trend(sent, refs)\n",
    "        if i: [incidents.append(x) for x in i]\n",
    "        if s: [statuses.append(x) for x in s]\n",
    "        if t: [trends.append(x) for x in t]\n",
    "    if incidents: print(index, incidents)\n",
    "    #if statuses: print(index, statuses)\n",
    "    #if trends: print(index, trends)\n",
    "    \n",
    "extract(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest = nlp(df['content'][0])\\nsents = [sent.as_doc() for sent in test.sents]\\ndisplacy.render(sents[1], style='dep', jupyter=True)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test = nlp(df['content'][0])\n",
    "sents = [sent.as_doc() for sent in test.sents]\n",
    "displacy.render(sents[1], style='dep', jupyter=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\na = nlp(df['content'][7])\\ndisplacy.render(a, style='ent', jupyter=True)\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a = nlp(df['content'][7])\n",
    "displacy.render(a, style='ent', jupyter=True)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
